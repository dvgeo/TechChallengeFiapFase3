# FIAP Tech Challenge Fase 3 - API para Monitoramento de Press√£o em Redes Hidr√°ulicas, Modelo de Machine Learning para Detec√ß√£o de Anomalias e Aplica√ß√£o Streamlit com Modelo Treinado 

![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![AWS S3](https://img.shields.io/badge/Amazon_S3-569A31?style=for-the-badge&logo=amazon-s3&logoColor=white)
![Google Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)

API para coleta de dados de sensores *Internet of Things*(*IOT*) de press√£o em redes de √°gua medidos em metros de coluna d'√°gua (mca) de um banco de dados PostgreSQL com armazenamento no datalake S3 AWS e treinamento de modelo de machine learning desenvolvido como parte do **FIAP Tech Challenge Fase 3** da p√≥s-gradua√ß√£o em Machine Learning Engineering.

## üë®‚Äçüíªüë®‚Äçüíª Autores
- *Diego Varela* **rm359642** 
- *Vagner F√°bio* **rm358795** 

## üìã Vis√£o Geral do Projeto

### Contexto do Projeto
Desenvolvido como parte do programa de p√≥s-gradua√ß√£o da FIAP, este projeto integra:
- **API FastAPI**: Para monitoramento em tempo real
- **Armazenamento em Nuvem**: Dados hist√≥ricos no AWS S3
- **Machine Learning**: Modelos preditivos para detec√ß√£o de anomalias

## ‚ú® Principais Funcionalidades

### API
- Consulta de dados hist√≥ricos (√∫ltimo ano)
- Dados do dia corrente
- Geolocaliza√ß√£o dos sensores
- Estat√≠sticas de medi√ß√µes (m√©dias e desvios padr√£o)
- Sistema de alertas de anomalias

### Arquitetura Integrada
1. **Coleta de Dados**: Sensores IoT enviando dados para PostgreSQL
2. **API de Consulta**: FastAPI para acesso aos dados Postgresql
3. **Armazenamento Cloud**: Script python para armazenamento de dados consolidados em Parquet na AWS S3
4. **An√°lise Preditiva**: Modelos ML treinados no Google Colab

## üöÄ Instala√ß√£o

## 1. Clone o reposit√≥rio:
```bash
git clone https://github.com/seu-usuario/repositorio.git
cd repositorio
```
## 2. Crie e ative o ambiente virtual:

```
python -m venv venv
source venv/bin/activate  # Linux/MacOS
venv\Scripts\activate  # Windows
```

## 3. Instale as depend√™ncias:

```
pip install -r requirements.tx
```

## 4. Crie um arquivo .env na raiz do projeto com as seguintes vari√°veis:
## ‚öô Configura√ß√£o

```
Configura√ß√µes PostgreSQL 
POSTGRES_DB_SCADA=nome_banco
POSTGRES_USER_SCADA=usuario
POSTGRES_PASSWORD_SCADA=senha
POSTGRES_HOST_SCADA=host
POSTGRES_PORT_SCADA=porta

Configura√ß√µes AWS
AWS_ACCESS_KEY_ID=sua_chave
AWS_SECRET_ACCESS_KEY=sua_secreta
S3_BUCKET=meu-bucket
```

## 5. Execute a API FastAPI:

```
uvicorn main:app --reload
```

## üìö Documenta√ß√£o da API
Endpoints dispon√≠veis
### 1. Dados Gerais


http

`GET /dados_geral`

Retorna dados hist√≥ricos dos √∫ltimos 12 meses

**Par√¢metros**:

Nenhum

**Exemplo de Resposta**:

```bash
JSON
[
  {
    "xid": "DP_060785",
    "hora": "16",
    "data": "2025-03-25",
    "media_hora": 10.91,
    "desvio_padrao_30_dias": 0.75,
    "alerta": "Anormal",
    "tipo": "A",
    "latitude": -7.5506507,
    "longitude": -35.9333824,
    "bairro": "ROGER"
  }
]
```
### 2. Dados do Dia

http

`GET /dados_dia`

Retorna dados da √∫ltima hora registrada do dia corrente

**Par√¢metros**:

Nenhum

**Resposta**:

```bash
JSON
[
  {
    "xid": "DP_060785",
    "hora": "16",
    "data": "2025-03-31",
    "media_hora": 14.11,
    "desvio_padrao_30_dias": 0.78,
    "alerta": "Anormal",
    "tipo": "A",
    "latitude": -7.524874,
    "longitude": -35.845154,
    "bairro": "MANGABEIRA"
  }
]
```
## Acesse a documenta√ß√£o interativa:

- Swagger UI: `http://localhost:8000/docs`

- Redoc: `http://localhost:8000/redoc`

## üîÑ 6. Integra√ß√£o com S3
O script `s3_loader.py` realiza as seguintes opera√ß√µes:

1. Conecta ao bucket S3 configurado.

2. Carrega arquivo Parquet no bucket AWS S3 na pasta `scada/dados_pressao.parquet`

## üîÑ 7. Pipeline de Machine Learning para Detec√ß√£o de Anomalias em Dados SCADA

Este modelo de machine learning realiza a detec√ß√£o de comportamentos an√¥malos em sensores de press√£o, utilizando dados hist√≥ricos armazenados em um bucket S3 no formato Parquet. O pipeline inclui o pr√©-processamento, treinamento de um modelo de Machine Learning (XGBoost), e um dashboard interativo com Streamlit para visualiza√ß√£o e predi√ß√£o em tempo real.

---

## üìÅ Estrutura do Projeto

- `treinar_modelo_alerta.py` ‚Üí script de treinamento do modelo com dados reais e sint√©ticos
- `dashboard.py` ‚Üí aplica√ß√£o com Streamlit para predi√ß√£o com o modelo treinado
- `modelo_alerta_xgboost_sintetico.pkl` ‚Üí modelo salvo ap√≥s o treinamento

---

## üîç Descri√ß√£o do Treinamento (`treinar_modelo_alerta.py`)

1. **Coleta de dados** do S3 (`.parquet`) com autentica√ß√£o segura.
2. **Limpeza** de valores nulos e negativos.
3. **Engenharia de features**:
   - `dif_media = media_hora - media_hora_30_dias`
   - `media_hora_relativa = media_hora / (media_hora_30_dias + 1)`
4. **Gera√ß√£o de dados sint√©ticos** de alerta para balancear a base.
5. **Treinamento com XGBoost**, utilizando `scale_pos_weight` para lidar com desbalanceamento.
6. **Avalia√ß√£o com m√©tricas** de classifica√ß√£o.
7. **Salvamento do modelo** com `joblib`.

---

## üìä Aplica√ß√£o(`app.py`)

- Leitura do modelo `.pkl`
- Interface para entrada de dados manuais ou via API
- Predi√ß√£o do alerta com base nas vari√°veis de entrada
- Exibi√ß√£o do resultado de forma clara e responsiva

---

## ‚ñ∂Ô∏è Como Executar

### 1. Instalar depend√™ncias:

```bash
pip install -r requirements.txt
```

Ou diretamente:

```bash
pip install pandas numpy scikit-learn matplotlib seaborn fastapi uvicorn joblib streamlit imbalanced-learn s3fs pyarrow xgboost
```

### 2. Treinar o modelo (opcional):

```bash
python treinar_modelo_alerta.py
```

### 3. Rodar o Aplicativo:

```bash
streamlit run app.py
```

---

## üì¶ Requisitos

- Python 3.8+
- Acesso √† AWS com credenciais v√°lidas no Colab ou ambiente local
- Streamlit para rodar o dashboard


